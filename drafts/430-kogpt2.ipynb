{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\n",
      "우리나라에서 제일 높은 산은 일본이다.\n",
      "조선의 태조 이성계의 셋째 아들인 경숙종이 태어나서 태어나서 제일 높은 산은 명주군 조씨성이다.\n",
      "명주군 조씨는 태조 이성계의 둘째 아들이다.\n",
      "이런 조선의 3대 절경 중 하나인 효장산(孝莊山)은 고려 초기의 명산이라 할 만하다.\n",
      "이곳은 고려 태조 이성계가 살던 곳이고, 그 이전에 고려 태조 왕건의 생모가 살았었다.\n",
      "삼국 시대에도 효장산에 대해 많은 기록이 남아 있다.\n",
      "태조 왕건이 태어난 곳으로 전해졌다고도 한다.\n",
      "태조 왕건의 생가인 조씨 산성은 본래 조선 태조의 둘째 딸 능경(陵景)과 형제처럼 지냈다.\n",
      "능경 산성이 고려 시대 태조 왕건에게 왕위를 이양하기 위해 이곳으로 옮겨와 조성한 무덤이었기 때문이다.\n",
      "덕성산의 꼭대기가 고려 태조의 첫째 딸을 낳았을 때 이 무덤에서 태어났다.\n",
      "태조 왕건이 죽었을 때 이 무덤에서 태어났다.\n",
      "숙종은 어려서 효장산에 들어가 죽었고, 이 무덤은 효장산과 함께 조선 역사의 상징이었다.\n",
      "조선시대에는 효장산에 제사를 지내고 있다.\n",
      "지금도 이 무덤에는 고려 왕건이 묻힌 능경 무덤과 같은 곳에 있다.\n",
      "조선 왕조의 마지막 왕인 숭덕종은 혜종 때 태어나 명주군 조씨 산성에 묻혔다.\n",
      "숙종 때에도 효장산에 제사를 지내고 있다.\n",
      "다만 효장산 주변에는 태조 왕건의 능경 묘가 남아있다.\n",
      "능경이 살았던 것으로 알려져 있다.\n",
      "조선의 태조 왕건 역시 효장산 입구에 사당을 세웠지만, 실제로 이 묘를 찾을 수 없다.\n",
      "일제강점기 이전까지 이 묘에는 묘 앞에서 제사를 드리고, 무덤에서 제사를 지냈던 것으로 전한다.\n",
      "하지만 일제강점기 이후 이 묘를 찾는 일이 줄어들었다고 한다.\n",
      "명산 일대에 묘역이 많은 것에 대해서는 문화재로 지정받기 어렵다는 의견이 지배적이다.\n",
      "조선 시대 최고의 사찰인 명산시 남산에는 덕성사와 명동성당, 선암사가 있다.\n",
      "남산과 선암사가 있는 이곳에 조선 시대 최초의 사액서원(賜額書院)이 세워진 것이다.\n",
      "조선 시대 최고의 사찰에 지정된 것은 중종 때 일이다.\n",
      "선암사에는 덕성사를 창건한 조광조가 직접 참배했으며, 선암사에서 직접 제사를 지내며, 선조 때부터 선암사로 들어가던 모습도 있다.\n",
      "선암사에는 효종 때 처음 만들어진 명동성당과 선암 스님들이 머물렀던 선암사도 있다.\n",
      "조선 시대 최초의 사액서원(賜額書院)인 효장산 선암선원에서는 효장산 남쪽에 있는 선암사의 동쪽에 위치해 있어 선조의 위패를 모시는 곳이라고 볼 수 있다.\n",
      "이런 선암사 안에 있는 조씨 묘에서는 효장산 중턱에 조성된 능경 묘비가 유일하게 남아 있다.\n",
      "선암 선암사 입구쪽에서는 효장산 정상 부근에 조성된 선암사의 표지석 일부를 볼 수 있다.\n",
      "선암사는 조선 시대 최고의 사찰이며 그 역사적 의미가 크다.\n",
      "선암사는 조선시대 대표적인 선암사라고 할 수 있는데, 그 유래는 숙종 때이다.\n",
      "숙종 때 건립된 선암사는 선암사 입구쪽인 조남문(曹南門)을 중심으로 삼백리, 삼백리, 삼백리, 삼백리, 삼백리, 삼백리 등 13구의 능묘에 둘러싸여 있다.\n",
      "묘 안에는 선암사 경조사가 보관하기도 했다.\n",
      "선조들 중에 효장산에 올라 선암사에서 본 적 있는 분재를 보았다는 조씨의 글이 전해지고 있다.\n",
      "선암사를 둘러보며 선조로부터 효장산에서 선암사에 올랐다는 이야기를 들었기 때문이다.\n",
      "조선 시대 최고의 사찰을 선정하고 관리하는 것은 매우 중요하다.\n",
      "조선 시대 최고의 사찰인 선암사에서 선조들이 효장산에 오른 것을 어떻게 기록할 수 있을까.\n",
      "조선시대 최초의 사액서원은 선조에게 효장산에 올라서 선암사를 올랐다는 글을 남긴 조씨 능경(陵景)에 대해 기록하고 있다.\n",
      "선조들이 효장산에서 선암사를 오른 뒤 선암사에서 사재를 내면서 선암사에는 조씨가 묻혀 있었다는 이야기를 엿볼 수 있다.\n",
      "선조들은 선조대에 효장산에서 선암사를 오른 뒤 선암사에 들어갔다고 전해진다.\n",
      "능경에서는 선암사 입구쪽 선암사 입구에서 사재를 냈지만, 선암사 입구쪽 선암사에 오르기도 했다는 얘기들이 전해진다.\n",
      "선조들의 선암사에 대한 연구가 없었는데, 선조들이 선암사에 올라 선암사를 올랐다는 이야기가 나온다.\n",
      "선조들은 선암사를 오르며, 선암사에 올라 선암사에 올랐다는 이야기를 전한다.\n",
      "선조들은 선조에게 효장산에서 올라 선암사로 올라 선암사에 올랐다는 이야기와 선암사에 올라서 선암사를 올랐다는 이야기를 들었던 것이다.\n",
      "선암사는 선암사의 첫 번째 선암사였다.\n",
      "선조들은 선조들이 효장산에 올라 선암사를 봤을 때 조씨가 머물렀다는 얘기를 했다.\n",
      "선조들이 선암사에 올라 선암사를 보았던 기록이 남아있다는 것이다.\n",
      "선조들은 선암사에서 선암사에 올랐고 선암사의 첫 번째 선암사를 보았다는 이야기를 기록으로 남겼다.\n",
      "선조들은 선암사를 보고 선조가 얼마나 선암사를 좋아했던가에 대해서도 생각해보게 된다.\n",
      "선조들은 선암사에 오르는 선조들의 모습을 보며 선조들이 선암사가 있었기에 선조가 어떤 생각을 했던 것이란 것을 알게 된다.\n",
      "선조들은 선암사가 선조들의 묘가 됐기 때문이라고 말한다.\n",
      "선조들의 묘를 모신 사당인 선암사는 조선 후기에 들어서자 임진왜란 당시 왜군을 물리치고 평남 지역의 중심 도시 중 하나였다.\n",
      "선암사는 본래 선암사는 안강사였는데, 임진왜란 때 패망한 선조가 머물터였던 곳이다.\n",
      "선조들은 임진왜란 때 패망한\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"우리나라에서 제일 높은 산은\", add_special_tokens=False, return_tensors=\"pt\")\n",
    "# output_sequences = model.generate(input_ids=input_ids, do_sample=True, max_length=100, num_return_sequences=3)\n",
    "output_sequences = model.generate(input_ids=input_ids, do_sample=True, max_length=1000)\n",
    "for i, sequence in enumerate(output_sequences):\n",
    "    text = tokenizer.decode(sequence.tolist(), clean_up_tokenization_spaces=True)\n",
    "    print(f\"\\n[{i}]\\n{text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- https://huggingface.co/skt/kogpt2-base-v2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
